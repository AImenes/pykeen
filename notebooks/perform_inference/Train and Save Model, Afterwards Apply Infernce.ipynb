{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pykeen\n",
    "from pykeen.kge_models import TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger('pykeen').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1 (default, Nov  6 2018, 18:45:35) \n",
      "[Clang 10.0.0 (clang-1000.11.45.5)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  5 14:12:18 2019\n"
     ]
    }
   ],
   "source": [
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.23\n"
     ]
    }
   ],
   "source": [
    "print(pykeen.get_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which hyper-parameters are required by TransE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_dim',\n",
       " 'margin_loss',\n",
       " 'learning_rate',\n",
       " 'scoring_function',\n",
       " 'normalization_of_entities']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransE.hyper_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = '../data/trained_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate TransE (provide test set):\n",
    "* Define the path to our test set: **test_set_path**\n",
    "* Define whether you want to compute the metrics (mean rank and hits@k) in raw or in a filtered setting: **filter_negative_triples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    training_set_path           = '../../data/rdf.nt',\n",
    "    test_set_path               = '../../data/rdf.nt', # Just for illustration, we use the training set also as test set\n",
    "    execution_mode              = 'Training_mode',\n",
    "    random_seed                 = 2,\n",
    "    kg_embedding_model_name     = 'TransE',\n",
    "    embedding_dim               = 100,\n",
    "    scoring_function            = 1,  # corresponds to L1\n",
    "    normalization_of_entities   = 2,  # corresponds to L2\n",
    "    margin_loss                 = 3,\n",
    "    learning_rate               = 0.1,\n",
    "    num_epochs                  = 100,  \n",
    "    batch_size                  = 32,\n",
    "    filter_negative_triples     = True,\n",
    "    preferred_device            = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate TransE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehdi/virtual_envs/pykeen_python_3_7/lib/python3.7/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "INFO:pykeen.utilities.pipeline:-------------Train KG Embeddings-------------\n",
      "Training epoch: 100%|██████████| 100/100 [00:00<00:00, 149.25it/s]\n",
      "INFO:pykeen.utilities.pipeline:-------------Start Evaluation-------------\n",
      "INFO:pykeen.utilities.evaluation_utils.metrics_computations:Evaluation took 0.26s seconds\n"
     ]
    }
   ],
   "source": [
    "results = pykeen.run(\n",
    "    config=config,\n",
    "    output_directory=output_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check result entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['trained_model', 'losses', 'entity_to_embedding', 'relation_to_embedding', 'eval_summary', 'entity_to_id', 'relation_to_id', 'final_configuration'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get evaluation results:\n",
    " * Mean rank\n",
    " * Hits@k, k $\\in$ {1,3,5,10} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_rank': 0.0660377358490566,\n",
       " 'hits@k': {1: 0.9339622641509434, 3: 1.0, 5: 1.0, 10: 1.0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.results['eval_summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare inference workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to model directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = output_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to data directory:\n",
    "* Should contain the candidate entities as *entities.txt*\n",
    "* Should contain the candidate relations as *relations.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.predict import start_predictions_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_predictions_pipeline(model_directory=model_directory,\n",
    "                          data_directory=data_directory,\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
